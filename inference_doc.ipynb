{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference from model training"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Two models were trained using two data-sets:\n",
    "- A synthetic datset made by chatGPT by giving the basic input necessary and asking it to synthesize the data\n",
    "- Using the sample given as the train test data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We saw that the model performed extremely well when the sample data was used:\n",
    "- This may be mostly because the validation, train and test data were mostly the same"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model trained on synthetic data does not perform well on the test data:\n",
    "- Although it is able to ascertain certain entities from the sample, majority of the entities are either missclassified or not detected\n",
    "- The major reasons for this happening are the following:\n",
    "    - No diversity in synthetic data: Almost all the data is exactly similar to each other\n",
    "    - No similarity of synthetic data to the actual data: Although the entites are present their occurence and the general structure of data is different"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary:"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As the main aim of the model was to develop a poc within the given amount of time, I think we have made a stride towards it and with further ingestion of data the model will start performing better"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Further improvements:"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The code structure is rudementary right now with a number of sequential operations taking place which don't impact the speed right now but will require parallelizations when scale is required\n",
    "- Only spacy approach was tested, further investigations can be made to include better techniques for implementing NER, for example: flair, bi-LSTM\n",
    "- Access to better/relatable data\n",
    "- Better code documentation"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a09a259b3deea77ce81e400f2432aa45f0ade5f76ece4a5b15b7853c2ebc9626"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
